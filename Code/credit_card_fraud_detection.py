# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_xCuwKmtAFVm_yISwotmfJbdBvVOslP

<B><H1>CREDIT CARD FRAUD DETECTION </H1><B>
<H3>Vandana Yalla </H3>

Uploading & Exploring the Data
"""

import pandas as pd

data = pd.read_csv("creditcard.csv")

data.head()

pd.options.display.max_columns = None

data.head()

data.tail()

data.shape

print("Number of columns: {}".format(data.shape[1]))
print("Number of rows: {}".format(data.shape[0]))

data.info()

data.isnull().sum()

data = data.dropna()
data.head()

data.isnull().sum()

data.describe()

from sklearn.preprocessing import StandardScaler

#Normalising the Amount Column
sc = StandardScaler()
data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))

data.head()

# Removintg the Time column as it is not relevant in this context
data = data.drop( ['Time'], axis =1 )

data.head()

data.duplicated().any()

data = data.drop_duplicates()

data.shape

data['Class'].value_counts()

"""We can see above that we have a highly imbalanced data set."""

import seaborn as sns
import matplotlib.pyplot as plt

#sns.countplot(data['Class'])
#plt.show()

#counts = data["Class"].value_counts()
#plt.bar(counts.index, counts.values)
sns.countplot(x= 'Class',hue= 'Class', data =  data, palette = "pastel")
plt.show()

"""**Proceeding with ML Models without rectificing the Imbalance in the Dataset**"""

X = data.drop( 'Class' , axis = 1 )
y = data['Class']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

classifier =  {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree Classifier": DecisionTreeClassifier(),
    "Random Forest Classifier": RandomForestClassifier()
}
for name,clf in classifier.items():
  print(f"\n----------{name}----------")
  clf.fit(X_train, y_train)
  y_pred = clf.predict(X_test)
  print(f"\n Accuracy Score: {accuracy_score(y_test,y_pred)}")
  print(f"\n F1 Score: {f1_score(y_test,y_pred)}")
  print(f"\n Precision Score: {precision_score(y_test,y_pred)}")
  print(f"\n Recall Score: {recall_score(y_test,y_pred)}")

"""**UNDER SAMPLING**"""

normal = data[data['Class'] == 0]
fraud = data[data['Class'] == 1]

normal.shape

fraud.shape

normal_sample = normal.sample(n= 473)

normal_sample.shape

new_data = pd.concat([normal_sample, fraud], ignore_index=True)

new_data.head()

new_data.shape

new_data['Class'].value_counts()

X0 = new_data.drop( 'Class' , axis = 1 )
y0 = new_data['Class']

X0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, test_size = 0.2, random_state = 42)

classifier =  {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree Classifier": DecisionTreeClassifier(),
    "Random Forest Classifier": RandomForestClassifier()
}
for name,clf in classifier.items():
  print(f"\n----------{name}----------")
  clf.fit(X0_train, y0_train)
  y0_pred = clf.predict(X0_test)
  print(f"\n Accuracy Score: {accuracy_score(y0_test,y0_pred)}")
  print(f"\n F1 Score: {f1_score(y0_test,y0_pred)}")
  print(f"\n Precision Score: {precision_score(y0_test,y0_pred)}")
  print(f"\n Recall Score: {recall_score(y0_test,y0_pred)}")

"""**OVER SAMPLING**"""

X1 = data.drop('Class', axis = 1)
y1 = data['Class']

X1.shape

y1.shape

from imblearn.over_sampling import SMOTE

X_res, y_res = SMOTE().fit_resample(X1,y1)

y_res.value_counts()

X1_train, X1_test, y1_train, y1_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)

classifier = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree Classifier": DecisionTreeClassifier(),
    "Random Forest Classifier": RandomForestClassifier()
}

for name, clf in classifier.items():
    print(f"\n----------{name}----------")
    clf.fit(X1_train, y1_train)
    y1_pred = clf.predict(X1_test)
    print(f"\n Accuaracy: {accuracy_score(y1_test, y1_pred)}")
    print(f"\n Precision: {precision_score(y1_test, y1_pred)}")
    print(f"\n Recall: {recall_score(y1_test, y1_pred)}")
    print(f"\n F1 Score: {f1_score(y1_test, y1_pred)}")

dtc = DecisionTreeClassifier()
dtc.fit(X_res, y_res)

import joblib

joblib.dump(dtc, "credit_card_model.pkl")

model = joblib.load("credit_card_model.pkl")

predict_1 =  model.predict([[-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]])

predict_1[0]

if predict_1[0] == 0:
    print("Normal Transcation")
else:
    print("Fraud Detected")